# pyhton-recosys

## 2. 기본적인 추천시스템

### 2.1. 데이터 읽기

### 2.2 인기제품 방식
* 개별 사용자 정보 X
* 간단한 추천 제공
* 모든 사용자들에게 동일한 제품(Best-Seller) 추천

### 2.3 추천시스템 정확도 측정
1. 훈련 데이터와 테스트 데이터로 나누기  
2. 정확도 측정하는 방법
  * RMSE 루트 민 스퀘어 에러   
    * n개의 데이터에 대해
    * (실제값-예측값) 제곱한 걸 더하고
    * n으로 나누고
    * 루트 씌우기  
    * 이 값이 **작아야** 좋은 것

### 2.4 사용자 집단별 추천
* 훈련 데이터와 테스트 데이터 분리
* 성별 기준으로 집단 분리


## 3. 협업 필터링 추천 시스템
* 실제 취향을 고려한 개인화 추천 시스템
* 이러한 아이디어로 만들어진 추천 알고리즘이 협업 필터링,   
  콜라보레이티브 필터링 CF
* 어떤 아이템에 대해 비슷한 취향을 가진 사람들은,  
  다른 아이템 또한 비슷한 취향을 가질 것이다

### 3.1. 협업 필터링의 원리
* 추천 대상과 취향이 비슷한 사람들의 집단이 먼저 만들어져 있다
* 취향이 비슷한 사람들을 찾아내기만 하면,  
  그 사람들이 좋아하는 아이템을 추천하면 된다  
* 유사도 계산 필요

### 3.2. 유사도 지표
* CF에서 사용자 간 유사도를 구하는 것이 핵심

#### 3.2.1. 상관계수
* 가장 이해하기 쉬운 유사도
* -1과 +1 사이의 값  
  * -1이면 부적 상관 관계, 음의 상관 관계 (우하향?)
  * +1이면 양의 상관 관계 (우상향?)
  * 0이면 지표가 점으로 나타나 연속적이지 않음, 유사하지 않게 나타남, 유사도가 0이라는 뜻  
  * 그런데 대문자 U 모양으로 쿼드러틱하게 나타나는 경우도 유사도가 0으로 표현된다
  * 단순히 상관 관계가 0이라고 해서 유사도가 없다고 생각하면 안 되고,  
    데이터를 실제로 비주얼라이제이션 해보거나 해서 정확한 인사이트를 얻어야 한다
* 평가 자료가 연속형인 경우 가장 이해하기 쉬운 유사도

#### 3.2.2. 코사인 유사도
* 협업 필터링에서 가장 널리 쓰이는 유사도
* 각 아이템 → 하나의 차원, 사용자의 평가값 → 좌표값
  * 예를 들면 x축은 아이템A, y축은 아이템B를 나타내고  
    점 C(x1, y1)에서 x1과 y1은 사용자C가 아이템A와 아이템B 각각에 대해 평가한 평가값을 나타낸다
* 두 사용자의 평가값 유사하다  
  → 코사인theta에서 theta는 작아지고 코사인 값은 커짐  
  (theta : 점A와 점B를 각각 원점과 이은 직선 사이의 각)
* -1과 +1 사이의 값
* 데이터가 이진값이라면(샀다 안 샀다/봤다 안 봤다) 타니모토 계수 사용 권장  

#### 3.2.3. 자카드 계수
* 타니모토 계수의 변형
* 이진수 데이터라면 협업 필터링에서 좋은 결과 나타난다

### 3.3. 기본 CF 알고리즘
> 1. 모든 사용자 간 평가의 유사도 계산  
> 2. 추천 대상과 다른 사용자 간 유사도 추출
> 3. 추천 대상이 평가하지 않은 아이템에 대한 예상 평가값 계산   
>  → 평가값 = 다른 사용자 평가 × 다른 사용자 유사도
> 4. 아이템 중에서 예상 평가값 가장 높은 N개 추천

### 3.4. 이웃을 고려한 CF
* 모든 사용자들과 유사도를 비교하는 게 아니고
* 정말로 유사도가 높은 사용자들을 선정해 예측치 판단
* 유사 집단을 정하는 방법 두 가지 KNN과 Thresholding

#### 3.4.1. KNN : K Nearest Neighbors
* 유사도가 높은 K개 선정

#### 3.4.2. Thresholding
* 미리 기준을 정해두고  해당 기준을 넘는다면 개수에 상관 없이 모두 채택
* 상관 계수 0.8 이상 또는 코사인 유사도 0.7 이상 등
* 일반적으로 KNN보다 정확

### 3.5. 최적의 이웃 크기 결정
* 집단의 크기가 너무 크면 best-seller 방식과 같이 개인의 취향이 반영되는 정도가 낮다
* 집단의 크기가 너무 작으면 신뢰성이 떨어짐

### 3.6. 사용자의 평가경향을 고려한 CF
* 같은 평점 다른 의미  
  * 평가를 높게 하는 사람, 평가를 낮게 하는 사람
* 집단과 사용자 간의 차이를 조정하는 고정치 필요

> 1. 각 사용자 평점 평균 계산
> 2. (각 상품의) 평점 -> 각 사용자의 평균에서의 차이로 변환  
> → 평점 - 해당 사용자의 평점 평균
> 3. 평점 편차의 예측값 계산  
> → 평가값 = 평점 편차 × 다른 사용자 유사도
> 4. 실제 예측값 = 평점편차 예측값 + 평점 평균

### 3.7. 이 외의 CF 정확도 개선 방법

#### 3.7.1. 신뢰도 가중 방법
* 어떤 사용자A와 0.8로 같은 유사도를 가진 사용자 B와 C가 있다고 가정했을 때,  
  * 사용자B는 사용자A와 공통으로 평가한 아이템 2개
  * 사용자C는 사용자A와 공통으로 평가한 아이템 10개

  → 사용자B 보다 사용자C의 신뢰도가 더 높다
* 따라서 신뢰도에 따라 유사도에 가중 하자
* 예측값은 매우 민감하기 때문에
  * 공통의 아이템 수를 직접적으로 반영을 하기보다
  * 공통으로 평가한 아이템의 수가 일정 개수 이상인 사용자들의 집단만 활용

### 3.8. 사용자 기반 CF와 아이템 기반 CF

#### 3.8.1 사용자 기반 CF : UBCF
* 지금까지는 사용자를 기준으로 비슷한 취향의 이웃 선정  
  * 취향이 비슷한 사용자 집단을 알아내서
  * 이 집단에 속한 사용자들이 공통으로 좋게 평가한 아이템 추천

* 사용자 기반 CF를 사용하는 경우
  * 데이터가 풍부한 경우 정확한 추천 가능
  * 가끔 결과에 대한 위험성 (엉뚱한 추천) 존재   

* 데이터 크기가 작고, 사용자에 대한 정보가 있는 경우 사용

#### 3.8.2 아이템 기반 CF : IBCF
* 유사도를 계산하는 기준이 아이템이면  
  > * 사용자들의 평가 패턴을 바탕으로
  > * 아이템 간의 유사도를 계산해서
  > * 특정 아이템에 대한 사용자의 예측 평점 계산
  
  다시 말해 
  > * 예측 대상인 사용자가 평가한 아이템의 평점과
  > * 다른 각 아이템과의 유사도를 가중평균해서
  > * 가중평균한 값을 특정 아이템에 대한 예측값으로 사용

* 아이템 기반 CF를 사용하는 경우
  * 계산이 빠르다
  * 업데이트에 대한 결과 영향이 적다  

* 데이터 크기가 크고, 충분한 정보가 없는 경우 사용

### 3.9. 추천 시스템의 성과 측정 지표
1. train/test set 분리
2. train set으로 학습, test set으로 평가
3. 예상 평점과 실제 평점 차이를 계산 후 정확도 측정

* 정확도 측정 방법

#### 3.9.1. 각 아이템의 예상 평점과 실제 평점 차이
* 지금까지 사용했던 RMSE → 연속적인 성격의 값에서 활용 가능

#### 3.9.2. 추천한 아이템과 사용자 실제 선택 비교
* 영화 평점 1 ~ 5 말고도  
  상품을 샀다 안 샀다, 영화를 봤다 안 봤다 등의  
  이진값인 경우도 많음

#### 3.9.3. 추천 시스템의 성과 측정 지표
| | |실제| |
|---|---|---|---|
| | | Positive | Negative |
| **예** | Positive | TP : True Positive | FP : False Positive |
| **측** | Negative| FN : False Negative | TN : True Negative |


1. 정확도 = 올바르게 예측한 아이템 수 / 전체 아이템 수  
    * 사용자가 선택했는지 뿐만 아니라 선택하지 않은 것도 올바르게 예측
    * (TP + TN) / (TP + TN + FP + FN)
2. 정밀도 = 올바르게 추천된 아이템의 수 / 전체 아이템 수
    * 추천 시스템이 10개를 추천했는데, 이 중 사용자가 실제로 6개 선택 → 0.6
    * TP / (TP + FP)
3. 재현율 = 올바르게 추천된 아이템의 수 / 사용자가 실제 선택한 전체 아이템 개수
    * 사용자는 총 12개 선택했는데, 이 중 6개가 추천된 아이템이었던 것 → 0.5
4. 정밀도와 재현율의 조화 평균(F1 score)   
  = (2 × 정밀도 × 재현율) / (정밀도 + 재현율)
    * 정밀도와 재현율을 동시에 고려하겠다
    * 정밀도와 재현율은 반비례 관계
5. 범위(coverage)
  = 추천이 가능한 사용자 수 (또는 아이템 수) / 전체 사용자 수 (또는 아이템 수)
    * 정밀도와 반비례 관계
6. TPR (True Postitive Rate) = TP / (TP + FN)
    * 정확하게 추천된 아이템의 비율
    * 사용자가 선택한 모든 아이템 중에서 추천 시스템이 제대로 추천해준 것
    * ≓ 재현율
7. FPR (False Positive Rate) = FP / (FP + PN)
    * 사용자가 선택하지 않은 아이템 중에서 추천 시스템이 추천한 아이템의 비율

   
* 추천 시스템이 사용자에게 추천한 아이템의 수 : TP + FP
* 사용자가 실제로 선택한 아이템 수 : TP + FN
* 현실에서 (TP + FP)와 (TP + FN)은 엄청 작은 수, TN은 엄청 큰 수    
→ TN이 들어가는 정확도는 1로, FPR은 0으로 수렴하는 등 정확한 추천이 어려울 수 있다
* 현실에서 사용할 수 있는 성과 측정 지표는 정밀도나 TPR, 그리고 이 둘을 같이 고려한 F1 Score 정도
